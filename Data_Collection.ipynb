{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUDWyAYc8o7F"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SecpvnrUvp0t",
        "outputId": "40abaece-89e2-44bb-9209-e2e6b801fa81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*****"
      ],
      "metadata": {
        "id": "RWu57yUptLRr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Author Implementation"
      ],
      "metadata": {
        "id": "vxp3BssGiydA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import argparse\n",
        "import sys"
      ],
      "metadata": {
        "id": "fHW95tVztNR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Given URL and path to save the content, this function extracts content of a given website\n",
        "def download_report(url, path):\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    response = requests.get(url, headers=headers)\n",
        "    file_extension = url.split('.')[-1]\n",
        "    path = path + '.' + file_extension\n",
        "    if response.status_code == 200:\n",
        "        # Get the content of the file\n",
        "        page_content = response.content\n",
        "\n",
        "        # Write the PDF content to the local file\n",
        "        with open(path, \"wb\") as file:\n",
        "            file.write(page_content)\n",
        "    else:\n",
        "        raise ValueError('Response not 200. Broken for: {}'.format(url))"
      ],
      "metadata": {
        "id": "nTazSMZftRxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The function retrives the stocks in various markets/ returns set of all unique tickers\n",
        "def get_all_tickers():\n",
        "    '''\n",
        "    Function to fetch the list of stocks in various US market indices\n",
        "    '''\n",
        "    sp500 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
        "    ticker_list_500 = sp500[0].Symbol.to_list()\n",
        "    sp400 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_400_companies')\n",
        "    ticker_list_400 = sp400[0].Symbol.to_list()\n",
        "    sp600 = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_600_companies')\n",
        "    ticker_list_600 = sp600[0].Symbol.to_list()\n",
        "    ticker_list = list(set(ticker_list_500 + ticker_list_400 + ticker_list_600))\n",
        "    return ticker_list"
      ],
      "metadata": {
        "id": "vq4B5lZ9tZC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(args):\n",
        "    with open(args.config_path) as json_file:\n",
        "        config_dict = json.load(json_file)\n",
        "    ticker_list = get_all_tickers()\n",
        "    for i, ticker in enumerate(ticker_list):\n",
        "        check_saved_path = os.path.join(config_dict['annual_reports_html_save_directory'], ticker)\n",
        "        if os.path.exists(check_saved_path):\n",
        "            continue\n",
        "        fmp_10k_url = 'https://financialmodelingprep.com/api/v3/sec_filings/{}?type=10-K&page=0&apikey={}'.format(ticker,\n",
        "                                                                                                                  config_dict['financial_modelling_prep_api_key'])\n",
        "        response = requests.get(fmp_10k_url)\n",
        "        for d in json.loads(response.content):\n",
        "            filing_type = d['type']\n",
        "            if not ((filing_type.lower() == '10-k') | (filing_type.lower() == '10k')):\n",
        "                continue\n",
        "            date_string = d['fillingDate']\n",
        "            date = date_string[:10]\n",
        "            year = date_string[:4]\n",
        "            if int(year) < 2002:\n",
        "                continue\n",
        "            link = d['finalLink']\n",
        "            save_path_directory = os.path.join(config_dict['annual_reports_html_save_directory'], ticker, date)\n",
        "            if not os.path.exists(save_path_directory):\n",
        "                os.makedirs(save_path_directory)\n",
        "            save_path = os.path.join(save_path_directory, date)\n",
        "            download_report(link, save_path)\n",
        "        print('Completed: {}/{}'.format(i+1, len(ticker_list)))"
      ],
      "metadata": {
        "id": "POuiF_M9tfpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = argparse.Namespace(config_path=\"/content/drive/My Drive/DS340/config.json\")"
      ],
      "metadata": {
        "id": "Apl3sJCOxTGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(args)"
      ],
      "metadata": {
        "id": "-8F08PIwxVTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modified Implementation"
      ],
      "metadata": {
        "id": "sj2JxozEirCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def main2(args):\n",
        "    with open(args.config_path) as json_file:\n",
        "        config_dict = json.load(json_file)\n",
        "    ticker_list = get_all_tickers()\n",
        "\n",
        "    # Select a random subset of indices of size 200\n",
        "    random_indices = random.sample(range(len(ticker_list)), 200)\n",
        "\n",
        "    for i in random_indices:\n",
        "        ticker = ticker_list[i]\n",
        "        check_saved_path = os.path.join(config_dict['annual_reports_html_save_directory'], ticker)\n",
        "        if os.path.exists(check_saved_path):\n",
        "            continue\n",
        "        fmp_10k_url = 'https://financialmodelingprep.com/api/v3/sec_filings/{}?type=10-K&page=0&apikey={}'.format(ticker, config_dict['financial_modelling_prep_api_key'])\n",
        "        response = requests.get(fmp_10k_url)\n",
        "        for d in json.loads(response.content):\n",
        "            filing_type = d['type']\n",
        "            if not ((filing_type.lower() == '10-k') | (filing_type.lower() == '10k')):\n",
        "                continue\n",
        "            date_string = d['fillingDate']\n",
        "            date = date_string[:10]\n",
        "            year = date_string[:4]\n",
        "            if int(year) < 2002:\n",
        "                continue\n",
        "            link = d['finalLink']\n",
        "            save_path_directory = os.path.join(config_dict['annual_reports_html_save_directory'], ticker, date)\n",
        "            if not os.path.exists(save_path_directory):\n",
        "                os.makedirs(save_path_directory)\n",
        "            save_path = os.path.join(save_path_directory, date)\n",
        "            download_report(link, save_path)\n",
        "        print('Completed: {}/{}'.format(i+1, len(ticker_list)))\n"
      ],
      "metadata": {
        "id": "TT_2ONElKTWk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}